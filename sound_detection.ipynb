{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "54275045-555f-4e67-8d2c-bb0e5b5f515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ec6c79f7-7a28-42af-a625-b20d8cb41a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the head pose cheat detection dataframe\n",
    "head_pose_df = pd.read_csv('head_pose_cheat_detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2f34ad6d-6dfb-4f8f-a0ae-2121b5ac4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "audio_file = 'G:/Exam-Proctoring-System/huangpi2.wav'\n",
    "audio_data, sampling_rate = librosa.load(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5ace1f8a-37b3-432e-baa4-1e491819d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the frame size and hop length (in samples)\n",
    "frame_length = int(0.04 * sampling_rate)  # Frame size in samples (40ms)\n",
    "hop_length = int(0.04 * sampling_rate)    # Hop length in samples (40ms, non-overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d794aaa1-4597-4fa3-8528-f4083cf2a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00819698 0.01091784 0.01082183 ... 0.00778981 0.00919653 0.0090942 ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the amplitude (e.g., using RMS) for each frame\n",
    "amplitudes = librosa.feature.rms(y=audio_data, frame_length=frame_length, hop_length=hop_length)\n",
    "print(amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "54d1829c-95d7-4469-a368-e37fe276942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold value in decibels\n",
    "threshold = 0.011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "19018d79-9229-4753-b2b3-1f6dc30c57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary representation\n",
    "binary_representation = (amplitudes > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "99b98926-bea9-4b6c-a76b-2b0235aa003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frame indices (timestamps)\n",
    "frame_indices = np.arange(binary_representation.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "73889066-9da0-4869-8f01-426fdb2d6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frame indices to timestamps (in seconds)\n",
    "timestamps_sec = frame_indices * (hop_length / sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "304b8d63-df4e-4251-8c65-2e802a59f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in head_pose_df for the binary values\n",
    "head_pose_df['sound_binary'] = np.nan  # Initialize with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "640aba11-b06b-4cfe-9cdf-563a18845524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the binary values to match the timestamps in head_pose_df\n",
    "video_timestamps = head_pose_df['Timestamp'].values / 1000  # Convert to seconds\n",
    "interpolator = interpolate.interp1d(timestamps_sec, binary_representation.flatten(), kind='nearest', fill_value='extrapolate')\n",
    "interpolated_binary = interpolator(video_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "10c2394b-a2d2-419d-96fb-2b56eee632e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'sound_binary' column with the interpolated values\n",
    "head_pose_df['sound_binary'] = interpolated_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "323128cc-bfc9-48ea-b14e-10fd8d3985d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataframe (e.g., to a CSV file)\n",
    "head_pose_df.to_csv('combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce8cb3-98e5-4aaf-aebe-f47988a96bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
